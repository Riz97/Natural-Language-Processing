{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "367ba310-ab5e-4327-a2af-06da85503dad",
   "metadata": {},
   "source": [
    "# Natural Language Processing Project \n",
    "\n",
    "# Word AutoCorrection from scratch \n",
    "\n",
    "# Riccardo Caprile 4370774"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1237ee74-a244-45b4-a3c8-6cff9a218666",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "K = 5 #rounding value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ae5327-6905-46a9-bb65-b0e03987a186",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c20faea-ffa4-4696-bf2f-6369714ec1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_file_processing(file):\n",
    "    words = []\n",
    "    with open (\"The_Hunger_Games.txt\", \"r\") as file:\n",
    "        file_name_data = file.read()\n",
    "        file_name_data_lower = file_name_data.lower()\n",
    "        words = re.findall(\"\\w+\",file_name_data_lower)#\\w+ matches any word character as many times as possible\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11bf41ac-ed8b-471d-976a-b78fe257a7d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----TEST PRINT----\n",
      "First  20 words :   ['when', 'i', 'wake', 'up', 'the', 'other', 'side', 'of', 'the', 'bed', 'is', 'cold', 'my', 'fingers', 'stretch', 'out', 'seeking', 'prims', 'warmth', 'but']\n",
      "First 20 unique words :  ['wee', 'refill', 'dismissed', 'befriending', 'demonstrated', 'efficiently', 'tea', 'pariahs', 'untouched', 'event', 'radical', 'pillowlay', 'donation', 'sponges', 'piercing', 'claim', 'clusters', 'misjudged', 'drastic', 'adjusting']\n",
      "7603\n"
     ]
    }
   ],
   "source": [
    "list_words = text_file_processing(\"The_Hunger_Games.txt\") #Contains all the words of the text\n",
    "list_words.remove(\"Ã¯\")\n",
    "\n",
    "vocabulary = set(list_words) #Contains all the unique worlds\n",
    "\n",
    "\n",
    "print(\"-----TEST PRINT----\")\n",
    "print(\"First  20 words :  \" , list_words[0:20]) \n",
    "\n",
    "\n",
    "\n",
    "print(\"First 20 unique words : \" , list(vocabulary)[0:20])\n",
    "print(len(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d58d74ac-8a91-4620-bf4e-75c34fa96afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(list_words):\n",
    "    \n",
    "    word_count = {}\n",
    "    word_count = Counter(list_words)\n",
    "    \n",
    "    return word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a717954f-a904-48ae-a3c1-f2323d5bfe30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------TEST PRINT--------\n",
      "Top 20 present words are:  [('the', 5649), ('i', 3785), ('to', 2754), ('and', 2424), ('a', 2152), ('of', 1936), ('my', 1632), ('in', 1489), ('it', 1016), ('me', 936), ('but', 925), ('that', 831), ('on', 775), ('he', 775), ('for', 726), ('you', 712), ('is', 685), ('with', 634), ('have', 596), ('as', 591)]\n",
      "There are 7603  keys\n"
     ]
    }
   ],
   "source": [
    "dictionary_count = count_words(list_words)\n",
    "\n",
    "print(\"-------TEST PRINT--------\")\n",
    "\n",
    "print(\"Top 20 present words are: \", Counter(dictionary_count).most_common(20))\n",
    "print(\"There are\" ,len(dictionary_count),\" keys\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea42b537-81f5-4370-9f22-703cb58aaa51",
   "metadata": {},
   "source": [
    "# Word Probabilities Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eaac03c2-645b-4661-9352-69150c541326",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_probabilities(dictionary_count):\n",
    "    \n",
    "    aux_word_probabilities = {}\n",
    "    \n",
    "    total_words = sum(dictionary_count.values())\n",
    "    \n",
    "    print(\"Total length of the corpus is : \" , total_words)\n",
    "    \n",
    "    for i in dictionary_count:\n",
    "        aux_word_probabilities[i] = dictionary_count[i]/total_words\n",
    "    \n",
    "    word_probabilities = {key : round(aux_word_probabilities[key],K) for key in aux_word_probabilities}\n",
    "    \n",
    "    return word_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd70bcf3-df70-44c8-a7f3-463f6b25dda1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total length of the corpus is :  100037\n",
      "----------\n",
      "Top 20 words with highest probability: \n",
      " [('the', 0.05647), ('i', 0.03784), ('to', 0.02753), ('and', 0.02423), ('a', 0.02151), ('of', 0.01935), ('my', 0.01631), ('in', 0.01488), ('it', 0.01016), ('me', 0.00936), ('but', 0.00925), ('that', 0.00831), ('on', 0.00775), ('he', 0.00775), ('for', 0.00726), ('you', 0.00712), ('is', 0.00685), ('with', 0.00634), ('have', 0.00596), ('as', 0.00591)]\n",
      "----------\n",
      "Total probability is :  1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "word_probabilities = word_probabilities(dictionary_count)\n",
    "\n",
    "\n",
    "print(\"----------\")\n",
    "print(\"Top 20 words with highest probability: \\n\", Counter(word_probabilities).most_common(20))\n",
    "print(\"----------\")\n",
    "print(\"Total probability is : \",math.floor(sum(word_probabilities.values())))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6798c5b-d385-4c8c-8888-4b08d60afca5",
   "metadata": {},
   "source": [
    "# String Edits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edaac6c8-cc3c-4b4e-8c0e-635facbbb3ab",
   "metadata": {},
   "source": [
    "Insert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7d17f66-e711-431b-a7e7-f44edd1f515e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_letter(word,prints = False):\n",
    "    \n",
    "    new_list = []\n",
    "    \n",
    "    alphabet = string.ascii_lowercase\n",
    "    \n",
    "    for i in range(len(word)+1):\n",
    "        \n",
    "        temp_list = [word[0:i] + new_letter + word[i:len(word)] for new_letter in alphabet]\n",
    "        \n",
    "        new_list.extend(temp_list)\n",
    "        \n",
    "    if prints == True : \n",
    "        print(\"The word got in input is -> \" , word , \"and the insert list is : \", new_list)\n",
    "    \n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4744ee7-9de5-40e1-a995-83dbb0295e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word got in input is ->  the and the insert list is :  ['athe', 'bthe', 'cthe', 'dthe', 'ethe', 'fthe', 'gthe', 'hthe', 'ithe', 'jthe', 'kthe', 'lthe', 'mthe', 'nthe', 'othe', 'pthe', 'qthe', 'rthe', 'sthe', 'tthe', 'uthe', 'vthe', 'wthe', 'xthe', 'ythe', 'zthe', 'tahe', 'tbhe', 'tche', 'tdhe', 'tehe', 'tfhe', 'tghe', 'thhe', 'tihe', 'tjhe', 'tkhe', 'tlhe', 'tmhe', 'tnhe', 'tohe', 'tphe', 'tqhe', 'trhe', 'tshe', 'tthe', 'tuhe', 'tvhe', 'twhe', 'txhe', 'tyhe', 'tzhe', 'thae', 'thbe', 'thce', 'thde', 'thee', 'thfe', 'thge', 'thhe', 'thie', 'thje', 'thke', 'thle', 'thme', 'thne', 'thoe', 'thpe', 'thqe', 'thre', 'thse', 'thte', 'thue', 'thve', 'thwe', 'thxe', 'thye', 'thze', 'thea', 'theb', 'thec', 'thed', 'thee', 'thef', 'theg', 'theh', 'thei', 'thej', 'thek', 'thel', 'them', 'then', 'theo', 'thep', 'theq', 'ther', 'thes', 'thet', 'theu', 'thev', 'thew', 'thex', 'they', 'thez']\n"
     ]
    }
   ],
   "source": [
    "word = \"the\"\n",
    "insertion_list = insert_letter(word, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82870efd-a632-47a8-aa13-98987b260d96",
   "metadata": {},
   "source": [
    "Delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ea3d46d-dab2-4ef5-a752-a764599a5e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_letter(word,prints = False):\n",
    "    \n",
    "    new_list = []\n",
    "        \n",
    "    temp_list = [word[0:i] + word[i+1 :len(word)] for i in range(len(word))]\n",
    "        \n",
    "    new_list.extend(temp_list)\n",
    "        \n",
    "    if prints == True : \n",
    "        print(\"The word got in input is -> \" , word , \"and the deletion list is : \", new_list)\n",
    "    \n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df92d2d1-4c47-402d-8b79-60748d775441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word got in input is ->  the and the deletion list is :  ['he', 'te', 'th']\n"
     ]
    }
   ],
   "source": [
    "word = \"the\"\n",
    "deletion_list = delete_letter(word,True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269f3b3f-cde4-43d4-8210-122bc97260d2",
   "metadata": {},
   "source": [
    "Swap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24dc9fda-68de-492d-ab71-67206a3bdb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap_letter(word,prints=False):\n",
    "    \n",
    "    new_list = []\n",
    "    \n",
    "    for i in range(len(word) -1):\n",
    "        \n",
    "        temp = list(word)\n",
    "        \n",
    "        temp[i] , temp[i+1] = temp[i+1] , temp[i]\n",
    "        \n",
    "        aux = ''.join(temp) # method to convert a list into a string\n",
    "        \n",
    "        new_list.append(aux)\n",
    "        \n",
    "    if word in new_list:\n",
    "        \n",
    "        new_list.remove(word)\n",
    "    \n",
    "    if prints == True : \n",
    "        print(\"The word got in input is -> \" , word , \"and the swap list is : \", new_list)\n",
    "    \n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63ce582a-9844-4053-940d-ba2a7f71a437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word got in input is ->  power and the swap list is :  ['opwer', 'pwoer', 'poewr', 'powre']\n"
     ]
    }
   ],
   "source": [
    "word = \"power\"\n",
    "swap_list = swap_letter(word,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f61985-9ad3-440d-93c4-0fe1ef74067e",
   "metadata": {},
   "source": [
    "Replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3682a62a-69f2-4ea6-9361-9c93f7ecac56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_letter(word,prints = False):\n",
    "    new_list = []\n",
    "    aux_list = []\n",
    "    alphabet = string.ascii_lowercase\n",
    "    \n",
    "    for i in range(len(word)):\n",
    "        \n",
    "        temp_list = [word[0:i] + replaced_letter + word[i+1 :len(word)] for replaced_letter in alphabet]\n",
    "        \n",
    "        temp_list.remove(word)\n",
    "        \n",
    "        aux_list.extend(temp_list)\n",
    "    \n",
    "    new_list = sorted(aux_list)\n",
    "        \n",
    "    if prints == True : \n",
    "        print(\"The word got in input is -> \" , word , \"and the replace list is : \", new_list)\n",
    "    \n",
    "    return new_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f266c5b-abb0-4697-ba4b-eea4301f98ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word got in input is ->  the and the replace list is :  ['ahe', 'bhe', 'che', 'dhe', 'ehe', 'fhe', 'ghe', 'hhe', 'ihe', 'jhe', 'khe', 'lhe', 'mhe', 'nhe', 'ohe', 'phe', 'qhe', 'rhe', 'she', 'tae', 'tbe', 'tce', 'tde', 'tee', 'tfe', 'tge', 'tha', 'thb', 'thc', 'thd', 'thf', 'thg', 'thh', 'thi', 'thj', 'thk', 'thl', 'thm', 'thn', 'tho', 'thp', 'thq', 'thr', 'ths', 'tht', 'thu', 'thv', 'thw', 'thx', 'thy', 'thz', 'tie', 'tje', 'tke', 'tle', 'tme', 'tne', 'toe', 'tpe', 'tqe', 'tre', 'tse', 'tte', 'tue', 'tve', 'twe', 'txe', 'tye', 'tze', 'uhe', 'vhe', 'whe', 'xhe', 'yhe', 'zhe']\n"
     ]
    }
   ],
   "source": [
    "word = \"the\"\n",
    "replace_list = replace_letter(word,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6c9833-d2a4-4fa4-8cf0-3d3f154397bd",
   "metadata": {},
   "source": [
    "# Combining string edit operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3966131-a914-4b8e-bfa4-bceb78cb72a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_one_words(word):\n",
    "    \n",
    "    dist_one = set(insert_letter(word) \n",
    "                   + delete_letter(word) \n",
    "                   + swap_letter(word) \n",
    "                   + replace_letter(word))\n",
    "    \n",
    "    return sorted(list(dist_one))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1ac12d3-64f9-41f2-8148-1d5d71e6f0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All the possible words at one edit distance from the word ---->  the \n",
      " ['ahe', 'athe', 'bhe', 'bthe', 'che', 'cthe', 'dhe', 'dthe', 'ehe', 'ethe', 'fhe', 'fthe', 'ghe', 'gthe', 'he', 'hhe', 'hte', 'hthe', 'ihe', 'ithe', 'jhe', 'jthe', 'khe', 'kthe', 'lhe', 'lthe', 'mhe', 'mthe', 'nhe', 'nthe', 'ohe', 'othe', 'phe', 'pthe', 'qhe', 'qthe', 'rhe', 'rthe', 'she', 'sthe', 'tae', 'tahe', 'tbe', 'tbhe', 'tce', 'tche', 'tde', 'tdhe', 'te', 'tee', 'teh', 'tehe', 'tfe', 'tfhe', 'tge', 'tghe', 'th', 'tha', 'thae', 'thb', 'thbe', 'thc', 'thce', 'thd', 'thde', 'thea', 'theb', 'thec', 'thed', 'thee', 'thef', 'theg', 'theh', 'thei', 'thej', 'thek', 'thel', 'them', 'then', 'theo', 'thep', 'theq', 'ther', 'thes', 'thet', 'theu', 'thev', 'thew', 'thex', 'they', 'thez', 'thf', 'thfe', 'thg', 'thge', 'thh', 'thhe', 'thi', 'thie', 'thj', 'thje', 'thk', 'thke', 'thl', 'thle', 'thm', 'thme', 'thn', 'thne', 'tho', 'thoe', 'thp', 'thpe', 'thq', 'thqe', 'thr', 'thre', 'ths', 'thse', 'tht', 'thte', 'thu', 'thue', 'thv', 'thve', 'thw', 'thwe', 'thx', 'thxe', 'thy', 'thye', 'thz', 'thze', 'tie', 'tihe', 'tje', 'tjhe', 'tke', 'tkhe', 'tle', 'tlhe', 'tme', 'tmhe', 'tne', 'tnhe', 'toe', 'tohe', 'tpe', 'tphe', 'tqe', 'tqhe', 'tre', 'trhe', 'tse', 'tshe', 'tte', 'tthe', 'tue', 'tuhe', 'tve', 'tvhe', 'twe', 'twhe', 'txe', 'txhe', 'tye', 'tyhe', 'tze', 'tzhe', 'uhe', 'uthe', 'vhe', 'vthe', 'whe', 'wthe', 'xhe', 'xthe', 'yhe', 'ythe', 'zhe', 'zthe']\n",
      "Number of all possible words at one edit distance 181\n"
     ]
    }
   ],
   "source": [
    "word = \"the\"\n",
    "test_list = dist_one_words(word)\n",
    "\n",
    "print(\"All the possible words at one edit distance from the word ----> \" , word , \"\\n\" , test_list )\n",
    "print(\"Number of all possible words at one edit distance\",len(test_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ca63855-bdb7-4389-9002-3c845710a3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_two_words(word):\n",
    "    \n",
    "    dist_two = []\n",
    "    \n",
    "    insert_aux_list = []\n",
    "    \n",
    "    delete_aux_list = []\n",
    "    \n",
    "    swap_aux_list = []\n",
    "    \n",
    "    replace_aux_list = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    dist_one_list = dist_one_words(word)\n",
    "    \n",
    "    aux_list = []\n",
    "    \n",
    "    for word in dist_one_list:\n",
    "        aux_list = insert_letter(word)\n",
    "        insert_aux_list.extend(aux_list)\n",
    "    \n",
    "    for word in dist_one_list:\n",
    "        aux_list = delete_letter(word)\n",
    "        delete_aux_list.extend(aux_list)\n",
    "        \n",
    "    for word in dist_one_list:\n",
    "        aux_list = swap_letter(word)\n",
    "        swap_aux_list.extend(aux_list)\n",
    "        \n",
    "    for word in dist_one_list:\n",
    "        aux_list = replace_letter(word)\n",
    "        replace_aux_list.extend(aux_list)\n",
    "        \n",
    "    \n",
    "    dist_two = set (insert_aux_list + \n",
    "                    delete_aux_list + \n",
    "                    swap_aux_list + \n",
    "                    replace_aux_list)\n",
    "        \n",
    "        \n",
    "    \n",
    "    return sorted(list(dist_two))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "18add1db-b7e3-4a3a-aa45-a36a5921af87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24254\n",
      "50 words at two edit distance from the word ------> what \n",
      " ['aaat', 'aahat', 'aaht', 'aat', 'aawhat', 'abat', 'abhat', 'abwhat', 'acat', 'achat', 'acwhat', 'adat', 'adhat', 'adwhat', 'aeat', 'aehat', 'aewhat', 'afat', 'afhat', 'afwhat', 'agat', 'aghat', 'agwhat', 'aha', 'ahaa', 'ahaat', 'ahab', 'ahabt', 'ahac', 'ahact', 'ahad', 'ahadt', 'ahae', 'ahaet', 'ahaf', 'ahaft', 'ahag', 'ahagt', 'ahah', 'ahaht', 'ahai', 'ahait', 'ahaj', 'ahajt', 'ahak', 'ahakt', 'ahal', 'ahalt', 'aham', 'ahamt']\n"
     ]
    }
   ],
   "source": [
    "word = \"what\"\n",
    "test_list_two = dist_two_words(word)\n",
    "\n",
    "\n",
    "print(len(test_list_two))\n",
    "print(\"Example of 50 words at two edit distance from the word ------>\", word, \"\\n\" , test_list_two[0:50])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacd1f55-6f5a-45fe-9192-896938aad236",
   "metadata": {},
   "source": [
    "# Word AutoCorrection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3e7a2736-c5c5-46a5-b9bf-2226c3d1c240",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordAutoCorrection (word,probabilities,vocab,n):\n",
    "    corrected_words = []\n",
    "    \n",
    "   \n",
    "    dist_one = set(dist_one_words(word))\n",
    "    \n",
    "    dist_two = set(dist_two_words(word))\n",
    "    \n",
    "    if word in vocab:\n",
    "        print(\"The word you inserted is : -----\" , word , \"----- and it is spelled correctly\")\n",
    "        corrected_words = word\n",
    "        return corrected_words\n",
    "    \n",
    "    elif(len(dist_one) != 0):\n",
    "        corrected_words = dist_one.intersection(set(vocab))\n",
    "        \n",
    "    elif(len(dist_two) != 0):\n",
    "        corrected_words = dist_two.intersection(set(vocab))\n",
    "    \n",
    "    if(len(corrected_words) == 0):\n",
    "        \n",
    "        corrected_words = word\n",
    "        print(\"Sorry , i wasn't able to analyze your word \", word , \"\\nTry with another one\")\n",
    "        return corrected_words\n",
    "        \n",
    "    dict_best_words = {k: probabilities[k] for k in corrected_words if k in probabilities}\n",
    "    \n",
    "    list_best_words = list(dict_best_words)\n",
    "\n",
    "    n_best_words = list_best_words[:n]\n",
    "    \n",
    "    print(\"The \" , n , \"words with the highest probability are : \" , n_best_words )\n",
    "    \n",
    "    return n_best_words\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2554aed7-b7ae-4608-a79f-f8a1a5b64737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the AutoCorrection project\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please , Enter a word ------>  watt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The  4 words with the highest probability are :  ['wait', 'waft', 'want']\n"
     ]
    }
   ],
   "source": [
    "print(\"Welcome to the AutoCorrection project\")\n",
    "word = input(\"Please , Enter a word ------> \")\n",
    "\n",
    "corrected_words = wordAutoCorrection(word,word_probabilities , vocabulary, 4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
